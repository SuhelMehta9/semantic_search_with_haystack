{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6207dcfe-ba55-4fee-88d0-b366dd8a18a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_haystack import QdrantDocumentStore\n",
    "from haystack.nodes import EmbeddingRetriever\n",
    "from haystack.nodes import PromptNode, PromptTemplate, AnswerParser\n",
    "from haystack.pipelines import Pipeline\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fcc8ec-1507-4caf-8b69-5d743bc86810",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = QdrantDocumentStore(\n",
    "    \"localhost\",\n",
    "    port = 6333,\n",
    "    index=\"test_data\",\n",
    "    content_field = \"content\",\n",
    "    name_field = \"name\",\n",
    "    embedding_field = \"vector\",\n",
    "    embedding_dim=384,\n",
    "    hnsw_config={\"m\": 16, \"ef_construct\": 64},\n",
    "    on_disk_payload = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41212e9-3f73-452a-9714-1a6f1543018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"tiiuae/falcon-7b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForCausalLM.from_pretrained(model, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc7b5f-783f-49f6-b93e-521e199671da",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = EmbeddingRetriever(\n",
    "    document_store=document_store,\n",
    "    embedding_model=\"sentence-transformers/multi-qa-MiniLM-L6-cos-v1\",\n",
    "    model_format=\"sentence_transformers\",\n",
    "    top_k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa20a2d-60de-44ac-9ab5-8cdc5369f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = PromptTemplate(\n",
    "    prompt=\"\"\"Answer the following question \\n\\n Related text: {join(documents)} \\n\\n Question: {query} \\n\\n Answer:\"\"\",\n",
    "    output_parser=AnswerParser())\n",
    "\n",
    "prompt_node = PromptNode(model, model_kwargs={\"model\":model, \"tokenizer\": tokenizer}, default_prompt_template=rag_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81ea67d-e54c-4d19-a830-1aec5c6fa34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline()\n",
    "pipe.add_node(component=retriever, name=\"retriever\", inputs=[\"Query\"])\n",
    "pipe.add_node(component=prompt_node, name=\"prompt_node\", inputs=[\"retriever\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091c7aa9-b74f-4fd3-818f-cf49b85767f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"who is father of Arya Stark\" # input()\n",
    "output = pipe.run(query=query)\n",
    "\n",
    "print(output[\"answers\"][0].answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
